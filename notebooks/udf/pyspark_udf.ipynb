{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import pandas_udf\nfrom pyspark.sql.types import StringType, ArrayType\nimport re\nimport pandas as pd\nimport traceback"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc76828e-a518-4045-93bb-fda9c2c73f5f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["@pandas_udf(ArrayType(StringType()))\ndef document_number_parser(rows, column):\n  '''\n  This UDF will parse the document numbers and fix the partial document numbers.\n  '''\n  def parse_doc_num(row, column):\n    res= []\n    try:\n      # To handle the fixing of partial document numbers, we require this for loop.\n      # because partial document numbers should only be fixed with their preceding \n      # full document number. We will loop over the document numbers and keep track\n      # of the last document number.\n      for item in row:\n        doc_num = re.search(\"\\d{2}[A-Z]\\d{6}\", item)\n        if doc_num and ((len(item) == 9) or (len(item) > 9 and not item[9].isdigit())):\n          res.append(doc_num.group(0))\n        elif \"partsdocumentnumber\" in column and len(item) <= 6 and item.isdigit() and len(res) != 0:\n          res.append(res[-1][:len(res[-1]) - len(item)] + \"\" + item)\n      return res\n    except Exception:\n      traceback.print_exc()\n      raise Exception(\"Error in parsing document number \" + row)\n\n  return pd.Series(map(lambda row, column : parse_doc_num(row, column), rows, column))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82d24304-8a7b-4ba6-9ec2-12db8ea0fcbb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark_udf","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3014004920734370}},"nbformat":4,"nbformat_minor":0}
